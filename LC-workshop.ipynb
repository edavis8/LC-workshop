{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with pandas dataframes\n",
    "\n",
    "## A soft introduction to data processing in Python\n",
    "\n",
    "\n",
    "### Lesson plan\n",
    "\n",
    "* Explore the Storywrangler Twitter ngram dataset using pandas\n",
    "* Use columns to isolate quantities of interest\n",
    "* Filter rows for subsets of the data\n",
    "* Formulate research questions from the data\n",
    "* Prepare Twitter data for visualization\n",
    "\n",
    "\n",
    "### Learning objectives\n",
    "* Learn basic pandas syntax\n",
    "* Use dataframe operations to make sense of large datasets\n",
    "* Manipulte dataframes to answer research questions\n",
    "* Prepare data for visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the pandas library\n",
    "import pandas as pd\n",
    "#otter is used for interactive grading\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a dataframe?\n",
    "\n",
    "A dataframe is a data structure arranged by rows and columns, and containing cells with data (like an Excel spreadsheet).\n",
    "\n",
    "\n",
    "### Why dataframes?\n",
    "\n",
    "Dataframes generally a stable format, unlike most excel spreadsheets; changing one cell will likely not affect other cells, and any change to the data is deliberate. It is relatively straightforward to get a subset of the data from a dataframe, with little risk of altering the original. \n",
    "\n",
    "Working with datasets in spreadsheets can quickly become confusing/onerous as the size of the dataset increases.\n",
    "\n",
    "Dataframes provide tools to navigate large datasets without scrolling through the data yourself.\n",
    "\n",
    "Spreadsheets + big data = danger\n",
    "\n",
    "But don't just take my word for it:\n",
    "\n",
    "* Small spreadsheet error costs company six billion dollars: https://qz.com/119578/damn-you-excel-spreadsheets-jp-morgan-edition/\n",
    "\n",
    "* Small spreadsheet error upends world financial policy: https://www.cc.com/video/dcyvro/the-colbert-report-austerity-s-spreadsheet-error\n",
    "\n",
    "* Errors in spreadsheets are the norm: https://arxiv.org/pdf/1602.02601\n",
    "\n",
    "### What is pandas?\n",
    "\n",
    "Pandas is a python library, and the industry/academic standard for dataframe operations in Python. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter ngrams example\n",
    "\n",
    "In the following lesson, we will use a dataset cherry picked from the much larger Storywrangler dataset of Twitter ngrams, `twitter-covid.csv`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset: Storywrangler Twitter ngrams\n",
    "\n",
    "* ngram - a string of words of characters of length *n*\n",
    "* ngrams counts collected from 1/10th of Twitter, and ranked for each day\n",
    "* The dataset contains the top 1 million 1-,2-,and 3-grams\n",
    "* Here we have a subset of that data containing keywords related to the COVID pandemic\n",
    "* The data here contain only 1-grams: individual words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem:\n",
    "\n",
    "In the following exercises, we will investigate how the **ranks** of various covid-related **ngrams** change over **time**. \n",
    "\n",
    "Specifically, how has usage of covid-related terms changed on Twitter since 2020, as shown by rank?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in data\n",
    "\n",
    "Much of the data we encounter will be in generic formats like .csv (comma separated values). These generic formats can generally be read into any programming language or spreadsheet software. Spreadsheet file formats like .xlsx can often be converted to .csv's. \n",
    "\n",
    "In pandas, the command for reading a csv is `pd.read_csv(filename)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The parse_dates argument tells pandas to recognize date strings,\n",
    "#and turn them into datetime objects\n",
    "twitter = pd.read_csv('twitter-covid.csv', parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Gathering basic information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get our hands dirty, let's get a general overview of the data. We can do this by using the `.head()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the .head(n) method gives us the first n rows of the dataframe\n",
    "twitter.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation\n",
    "\n",
    "Documentation is an essential resource when programming with libraries. It is likely that most problem you'd like to solve using the library have been anticipated by the authors, and are represented in the documentation. \n",
    "\n",
    "Official pandas web documentation:\n",
    "\n",
    "* https://pandas.pydata.org/docs/index.html\n",
    "\n",
    "Accessing documentation within Python:\n",
    "\n",
    "* For documentation on an object: `help(thing)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(twitter.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that Twitter produces an enormous amount of data, but just how big is our dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the .shape attribute tells us the dimensions of the dataframe\n",
    "twitter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, 159,402 rows is a lot of data.\n",
    "\n",
    "Would scrolling through all of it give us useful information, or would we be wasting our time?\n",
    "\n",
    "While this amount of data may seem intimidating at first, as data scientists we are well equipped to make some sense of it. \n",
    "\n",
    "That said, it's time to dissect the important parts of this data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Using columns\n",
    "\n",
    "We can use columns of the data to isolate quantities or metrics of interest for the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the .columns attribute will tell us the column names\n",
    "twitter.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the section of the DataFrame above, what are our columns of interest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select a single column in a pandas DataFrame use: `df[column_name]`\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter['count']\n",
    "#returns only the count column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select multiple columns use: `df[list_of_columns]`\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter[['ngram', 'count']]\n",
    "#returns both the ngram and count columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Now you try. Select the `date`, `ngram`, and `rank` columns. From the `twitter` DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###Your solution here v\n",
    "\n",
    "q1 = ...\n",
    "\n",
    "###Your solution here ^\n",
    "\n",
    "q1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check('q1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Selecting and filtering rows\n",
    "\n",
    "Now that we've isolated our columns of interest, how can we filter out the rows we need?\n",
    "\n",
    "One of the ways to select data by values is roughly: `data[true/false operation involving data]`\n",
    "\n",
    "Breaking this down in English: \"Select from the dataframe, rows such that the statement in brackets is true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets filter by `ngram`. We don't yet know which `ngrams` are in the dataset, and we can see from the snapshot above that ngrams are repeated in many rows for distinct dates. Therefore, we'd like to know the unique values contained in the `ngram` column. \n",
    "\n",
    "We can do this using the `.unique()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the .unique() method will return the unique elements of a column or row\n",
    "twitter['ngram'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the ngrams in the dataset are related to the covid pandemic, and come from different subjects within the discourse. Some are states or countries, while some are popular keywords. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by text\n",
    "\n",
    "Now, to select our n-grams of interest, we'll use what we learned with dates, insted applying the `.isin()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.isin() example\n",
    "twitter['ngram'].isin(['Brazil'])\n",
    "#Selects rows whose ngram column belongs to the list containing only 'Brazil'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Select only rows whose ngram is a country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#First, populate a list with the names of countries from the set above\n",
    "countries = ['Australia', 'Belgium', 'NZ', 'Brazil', 'India', 'Canada', 'US']\n",
    "\n",
    "#Now, select only the relevant data fromt the dataframe\n",
    "\n",
    "#Your answer here v \n",
    "\n",
    "q2 = ...\n",
    "\n",
    "#Your answer here ^\n",
    "\n",
    "print(set(q2['ngram']))\n",
    "\n",
    "q2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grader.check('q2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Selecting and filtering cont.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by Date\n",
    "\n",
    "We can filter by date in a similar fashion, using the `date` column instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#select only observations that occured before 2015\n",
    "twitter[twitter['date']<'2015-01-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using multilple conditions\n",
    "\n",
    "Similar to the above example, we can select using multiple conditions.\n",
    "Here, `&` denotes \"and\", and `|` denotes inclusive \"or\"\n",
    "\n",
    "For example: `df[(condition 1) & (condition 2)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only observations from between 2015 and 2016\n",
    "\n",
    "twitter[(twitter['date']>='2015-01-01') & (twitter['date']<'2016-01-01')]\n",
    "\n",
    "#notice each separate condition is in parentheses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Select only observations that occured before 2012 **or** after 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your answer here v\n",
    "\n",
    "q3 = ...\n",
    "\n",
    "#Your answer here ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check('q3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A brief detour\n",
    "\n",
    "You can easily use pandas to calculate summary statistics\n",
    "\n",
    "mean: `df[column].mean()`\n",
    "\n",
    "median: `df[column].median()`\n",
    "\n",
    "sum: `df.column.sum()`\n",
    "\n",
    "variance: `df[column].var()`\n",
    "\n",
    "standard deviation: `df[column].std()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean rank of \"Australia\": ',twitter[twitter['ngram']=='Australia']['rank'].mean())\n",
    "\n",
    "print('Standard deviation in rank of \"Australia\": ', format(twitter[twitter['ngram']=='Australia']['rank'].std(ddof=1),'.2f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Visualization and research ideation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Plot the rank of `'Australia'` on Twitter from 2020 to the present.\n",
    "\n",
    "First, we need to select the appropriate data from our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Select the appropriate data for the above question\n",
    "\n",
    "### Your answer here v\n",
    "\n",
    "q4 = ...\n",
    "\n",
    "### Your answer here ^\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check('q4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting python code\n",
    "\n",
    "#import plotting library\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import dates as mdates\n",
    "\n",
    "#create a blank figure\n",
    "fig, ax = plt.subplots(figsize=(12, 5.75))\n",
    "\n",
    "df = q4.set_index('date')\n",
    "\n",
    "\n",
    "ax.plot(df.index, df['rank'],label = 'Australia')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Rank')\n",
    "# set ticks to monthly\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "# format ticks\n",
    "plt.gcf().autofmt_xdate()\n",
    "# invert y axis (rank 1 should be on top)\n",
    "plt.gca().invert_yaxis()\n",
    "#display the legend\n",
    "plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "#ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making visualisations more intelligible\n",
    "\n",
    "This plot looks a bit messy. One thing we can do is implement a **rolling average**. We can take the mean of a sliding window within the data. This will give us a plot that looks less noisy, but preserves the overall trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show how .rolling() changes the dataframe\n",
    "twitter['rank'].rolling(14).median().head(28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute rolling 14-day average (mean)\n",
    "df = q4.set_index(pd.DatetimeIndex(q4['date']), drop=True)\n",
    "df = df.rolling('14d').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting python code\n",
    "fig, ax = plt.subplots(figsize=(12, 5.75))\n",
    "\n",
    "#plotting the data\n",
    "ax.plot(df.index, df['rank'], label = 'Australia')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Rank')\n",
    "# set ticks to monthly\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "\n",
    "# rotate ticks\n",
    "plt.gcf().autofmt_xdate()\n",
    "# invert y axis so rank 1 is on top\n",
    "plt.gca().invert_yaxis()\n",
    "# display legend\n",
    "plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Formulate your own simple research question using **up to five** of the available ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "### Your answer here v\n",
    "\n",
    "ngrams = [...]\n",
    "\n",
    "q5 = ...\n",
    "\n",
    "### Your answer here ^\n",
    "\n",
    "\n",
    "\n",
    "#plotting python\n",
    "\n",
    "#create empty figure\n",
    "fig, ax = plt.subplots(figsize=(12, 5.75))\n",
    "\n",
    "# plot each ngram separately\n",
    "for ngram in set(q5['ngram']):\n",
    "    # implement rolling 14-day average\n",
    "    q5 = q5.set_index(pd.DatetimeIndex(q5['date']), drop=True)\n",
    "    df_rolling = q5[q5['ngram']==ngram].rolling(14).mean()\n",
    "    # plot ngram and date\n",
    "    ax.plot(df_rolling.index, df_rolling['rank'], label = ngram)\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "\n",
    "#log axis helps keep high and low ranks visible\n",
    "plt.yscale('log')\n",
    "#formatting ticks\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.gca().invert_yaxis() \n",
    "#display legend\n",
    "plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Rank')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Is there any information shown in the above plots that could help you answer your research question?\n",
    "\n",
    "Can you think of any possible explanation for the behavior of your chosen ngrams?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your answer to q6 in this cell"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
